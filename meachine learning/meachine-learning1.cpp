1.机器学习方法 
	分为 有监督学习、无监督学习、半监督学习、增强学习

	1）有监督学习：从给定的有标注的训练数据集中学习出一个函数(模型参数)，当新的数据到来时可以根据这个函数预测结果
		分为分类(二分类)和回归(填空)。

	2）无监督学习：没有标注的训练数据集，需要根据样本间的统计规律对样本集进行分析，
		如聚类

	3）半监督学习：结合(少量的)标注训练数据和(大量的)未标注数据来进行数据的分类学习。
		两个基本假设：
		聚类假设：处在相同聚类中的样本示例有较大的可能拥有相同的标记，根据假设，决策边界就应该尽量通过数据较为稀疏的地方。
		流形假设：处于一个很小局部区域内的样本示例具有相似的性质。因此，其标记也应该相似。在假设下大量未标记示例的作用就是让
		数据空间变得更加稠密，从而有助于更加准确地刻画局部特性，使得决策函数能够更好地进行数据拟合。

	4）增强学习：外部环境对输出只给出评价信息而非正确答案下，学习机通过强化受奖励的动作来改善自身的性能。
		比如：教一个小孩子走路，不告诉他先走哪个脚，让他走，走不好就会摔，走好了给奖励，自然就会走路了。

	5）多任务学习：把多个相关的任务放在一起同时学习。具有更好的泛化能力。


2.机器学习面临的难题与挑战
	
	1）数据稀疏性

	2）高数量和高质量标注数据需求：获取标定数据需要耗费大量的人力和物力。

	3）冷启动问题: 产品初期，数据不足的问题

	4）泛化能力问题：训练数据不能全面、均衡的代表真实数据

	5）模型抽象困难：总结归纳问题中数学表示很难

	6）模型评估困难：实际问题中，很难定量评估一个模型的好还是不好

	7）寻找最优解困难

	8）Scalability是互联网的核心问题之一，搜索引擎索引的重要网页超过100亿，如果1台机器每秒处理1000网页，需要至少100天，所以
		出现了Spart, MPI...等分布式计算构架，选择什么样的计算平台，和算法设计紧密相关

	9）速度是互联网核心的用户体现。

	10）online learning：互联网每时每刻都在产生大量新数据要求模型随之不停更新，所以 online learning 是机器学习的一个重要研究方向。
	

